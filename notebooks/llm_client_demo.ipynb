{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a982280b",
   "metadata": {},
   "source": [
    "# LLM Client Usage Demo\n",
    "\n",
    "This notebook demonstrates how to use the `llm_client.py` module to create and interact with various LLM providers (OpenAI, Deepseek, Gemini) via the `LLMFactory`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba18cb83",
   "metadata": {},
   "source": [
    "## 2. Import LLM Client Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "231f2c27",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# ensure repo root is on path\n",
    "import sys\n",
    "sys.path.append(os.path.abspath(os.path.join(\"..\", \"\")))\n",
    "\n",
    "from src.core.llm_client import ModelProvider, LLMFactory, OpenAIClient, DeepseekClient, GeminiClient"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9803786d",
   "metadata": {},
   "source": [
    "## 3. Configure Environment Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "408eefc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "keys loaded? True True True\n"
     ]
    }
   ],
   "source": [
    "# either set in this cell (not recommended for secrets) or create a .env file\n",
    "load_dotenv()\n",
    "\n",
    "# example assignments (uncomment and fill with real keys if desired):\n",
    "# os.environ['OPENAI_API_KEY'] = 'your-openai-key'\n",
    "# os.environ['DEEPSEEK_API_KEY'] = 'your-deepseek-key'\n",
    "# os.environ['GEMINI_API_KEY'] = 'your-gemini-key'\n",
    "\n",
    "print(\"keys loaded?\", \n",
    "      'OPENAI_API_KEY' in os.environ, \n",
    "      'DEEPSEEK_API_KEY' in os.environ, \n",
    "      'GEMINI_API_KEY' in os.environ)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80751279",
   "metadata": {},
   "source": [
    "## 4. Instantiate Clients with Different Providers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "95962e5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<src.core.llm_client.OpenAIClient object at 0x000001DABC03FF20> <src.core.llm_client.DeepseekClient object at 0x000001DAB8721940> <src.core.llm_client.GeminiClient object at 0x000001DAB972A540>\n"
     ]
    }
   ],
   "source": [
    "# create clients via the factory\n",
    "openai_client = LLMFactory.create_client(ModelProvider.OPENAI, temperature=0.3)\n",
    "deepseek_client = LLMFactory.create_client(ModelProvider.DEEPSEEK, model_name='deepseek-chat', temperature=0.5)\n",
    "gemini_client = LLMFactory.create_client(ModelProvider.GOOGLE, model_name='gemini-flash-latest', temperature=0.7)\n",
    "\n",
    "print(openai_client, deepseek_client, gemini_client)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d1a7e39",
   "metadata": {},
   "source": [
    "## 4.1 Notes on warnings\n",
    "\n",
    "## 5. Generate Text with Each Client\n",
    "\n",
    "You may see output like object memory addresses or deprecation warnings. The memory addresses (e.g. `<src.core.llm_client.OpenAIClient object at ...>`) are just Python's default `repr` for the instances; the above change prints a friendly summary instead.\n",
    "\n",
    "Tqdm warnings can be resolved by installing and enabling `ipywidgets` in your Jupyter environment. The Google package deprecation message indicates you should migrate from `google.generativeai` to `google.genai` when updating your dependencies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e2c3f1a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- OpenAI ---\n",
      "Embrace the journey of learning with AI, where each interaction is a step towards unlocking the vast potential of human creativity and innovation. As we blend our curiosity with the boundless capabilities of artificial intelligence, we forge a path to a future where knowledge knows no bounds, and every challenge becomes an opportunity for growth and discovery.\n",
      "\n",
      "--- Deepseek ---\n",
      "Embrace the boundless curiosity of artificial intelligence as your companion, for it transforms the vast, uncharted ocean of human knowledge into a navigable river, guiding you toward shores of understanding you never dreamed you could reach. Let this synergy of silicon and spirit remind you that the greatest learning occurs not in replacing our wonder, but in using these brilliant tools to amplify it, propelling both our questions and our capabilities toward a brighter, more enlightened horizon.\n",
      "\n",
      "--- Gemini ---\n",
      "Embracing the power of artificial intelligence allows us to unlock hidden potential within our own minds, turning the vast ocean of human knowledge into a personalized journey of discovery that transcends traditional boundaries. By partnering with these digital mentors, we don't just process information faster; we ignite a lifelong flame of curiosity that empowers us to reshape the future with unprecedented wisdom and creative clarity.\n"
     ]
    }
   ],
   "source": [
    "prompt = \"Please give me a twoâ€‘sentence inspirational quote about learning with AI.  Make it at least 50 words.\"\n",
    "system = \"You are a helpful assistant.\"\n",
    "\n",
    "print(\"--- OpenAI ---\")\n",
    "print(openai_client.generate_text(prompt, system_prompt=system))\n",
    "\n",
    "print(\"\\n--- Deepseek ---\")\n",
    "print(deepseek_client.generate_text(prompt, system_prompt=system))\n",
    "\n",
    "print(\"\\n--- Gemini ---\")\n",
    "print(gemini_client.generate_text(prompt, system_prompt=system))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44d87fd8",
   "metadata": {},
   "source": [
    "## 6. Generate JSON with Each Client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "656c28dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a simple schema\n",
    "schema = {\n",
    "    \"type\": \"object\",\n",
    "    \"properties\": {\n",
    "        \"message\": {\"type\": \"string\"},\n",
    "        \"length\": {\"type\": \"integer\"}\n",
    "    },\n",
    "    \"required\": [\"message\", \"length\"]\n",
    "}\n",
    "\n",
    "json_prompt = \"Provide a JSON object containing an encouraging message and its character count.\"\n",
    "\n",
    "for client, name in [(openai_client, 'OpenAI'), (deepseek_client, 'Deepseek'), (gemini_client, 'Gemini')]:\n",
    "    print(f\"--- {name} JSON response ---\")\n",
    "    try:\n",
    "        result = client.generate_json(json_prompt, schema=schema, max_tokens=80)\n",
    "        print(result)\n",
    "    except Exception as e:\n",
    "        print(\"error\", e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d62cb02",
   "metadata": {},
   "source": [
    "## 7. Handle Errors and Validations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2acf3057",
   "metadata": {},
   "outputs": [],
   "source": [
    "# missing key example\n",
    "os.environ.pop('OPENAI_API_KEY', None)\n",
    "try:\n",
    "    LLMFactory.create_client(ModelProvider.OPENAI)\n",
    "except ValueError as e:\n",
    "    print(\"Expected error for missing key:\", e)\n",
    "\n",
    "# JSON parsing failure simulation: send bad prompt\n",
    "os.environ['OPENAI_API_KEY'] = 'dummy'\n",
    "class DummyClient(OpenAIClient):\n",
    "    def generate_text(self, prompt, max_tokens=None, system_prompt=None):\n",
    "        return \"not a json\"\n",
    "\n",
    "bad_client = DummyClient(api_key='abc', model_name='gpt-4o')\n",
    "try:\n",
    "    bad_client.generate_json('anything', schema={})\n",
    "except ValueError as e:\n",
    "    print(\"Caught JSON parse error:\", e)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
